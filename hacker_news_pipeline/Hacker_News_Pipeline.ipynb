{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3BU/rSo0/HRDQZZc0dgJs"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "For this Pipeline building task, the data we will use comes from a Hacker News (HN) API that returns JSON data of the top stories in 2014."
      ],
      "metadata": {
        "id": "Yby_IfoJ38tx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "L57oaMr3lmgs"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from pipeline import build_csv, Pipeline\n",
        "from stop_words import stop_words\n",
        "\n",
        "pipeline = Pipeline()\n",
        "\n",
        "import json\n",
        "import io\n",
        "import csv\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@pipeline.task()\n",
        "def file_to_json():\n",
        "  with open('hn_stories_2014.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "    stories = data['stories']\n",
        "    return stories"
      ],
      "metadata": {
        "id": "b_vWgVXVqSJJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stories = file_to_json()\n",
        "print(stories[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL3f-4UPx4bw",
        "outputId": "ca299b1f-05db-4bc9-8966-b0a15b565227"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'story_text': '', 'created_at': '2014-05-29T08:25:40Z', 'story_title': None, 'story_id': None, 'comment_text': None, 'created_at_i': 1401351940, 'url': 'https://duckduckgo.com/settings', 'parent_id': None, 'objectID': '7815290', 'author': 'TuxLyn', 'points': 1, 'title': 'DuckDuckGo Settings', '_tags': ['story', 'author_TuxLyn', 'story_7815290'], 'num_comments': 0, '_highlightResult': {'story_text': {'matchedWords': [], 'value': '', 'matchLevel': 'none'}, 'author': {'matchedWords': [], 'value': 'TuxLyn', 'matchLevel': 'none'}, 'url': {'matchedWords': [], 'value': 'https://duckduckgo.com/settings', 'matchLevel': 'none'}, 'title': {'matchedWords': [], 'value': 'DuckDuckGo Settings', 'matchLevel': 'none'}}, 'story_url': None}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@pipeline.task(depends_on=file_to_json)\n",
        "def filter_stories(stories):\n",
        "    def is_popular(story):\n",
        "        return story['points'] > 50 and story['num_comments'] > 1 and not story['title'].startswith('Ask HN')\n",
        "\n",
        "    return (\n",
        "        story for story in stories\n",
        "        if is_popular(story)\n",
        "    )"
      ],
      "metadata": {
        "id": "gc3v8vmCv5-P"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to csv\n",
        "@pipeline.task(depends_on=filter_stories)\n",
        "def json_to_csv(stories):\n",
        "  lines = []\n",
        "  for story in stories:\n",
        "    lines.append(\n",
        "        (story['objectID'], datetime.strptime(story['created_at'], \"%Y-%m-%dT%H:%M:%SZ\"), story['url'], story['points'], story['title'])\n",
        "        )\n",
        "    return build_csv(lines, header=['objectID', 'created_at', 'url', 'points', 'title'], file=io.StringIO())\n"
      ],
      "metadata": {
        "id": "z-Hhb-b_f4G-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract title column\n",
        "@pipeline.task(depends_on=json_to_csv)\n",
        "def extract_titles(csv_file):   # this return a generator of every story title\n",
        "  reader = csv.reader(csv_file)\n",
        "  header = next(reader)\n",
        "  print('header: ', header)\n",
        "\n",
        "  idx = header.index('title')\n",
        "  print('idx: ', idx)\n",
        "  return (line[idx] for line in reader)"
      ],
      "metadata": {
        "id": "MneY_SIimiu4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean the titles output\n",
        "@pipeline.task(depends_on=extract_titles)\n",
        "def clean_title(titles):\n",
        "  def inner(title):\n",
        "    processed = title.lower()\n",
        "    processed.replace(string.punctuation,\" \")\n",
        "    return processed\n",
        "  return (inner(title) for title in titles)\n",
        "\n",
        "# def clean_title(titles):\n",
        "#     for title in titles:\n",
        "#         title = title.lower()\n",
        "#         title = ''.join(c for c in title if c not in string.punctuation)\n",
        "#         yield title"
      ],
      "metadata": {
        "id": "tSMXq9nrpXet"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Word Frequency Dictionary\n",
        "@pipeline.task(depends_on=clean_title)\n",
        "\n",
        "# function that returns a dictionary of the word frequency of all\n",
        "# HN titles.\n",
        "def build_keyword_dictionary(titles):\n",
        "    word_freq = {}\n",
        "    for title in titles:\n",
        "        for word in title.split(' '):\n",
        "            if word and word not in stop_words:\n",
        "                if word not in word_freq:\n",
        "                    word_freq[word] = 1\n",
        "                word_freq[word] += 1\n",
        "    return word_freq"
      ],
      "metadata": {
        "id": "8UNclDaLqlKg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort the top words\n",
        "# pipeline.task() function that depends on the build_keyword_dictionary() function\n",
        "@pipeline.task(depends_on=build_keyword_dictionary)\n",
        "\n",
        "# function that returns a list of the top 100 tuples\n",
        "def top_words(word_freq):\n",
        "    freq_tuple = [\n",
        "        (word, word_freq[word])\n",
        "        for word in sorted(word_freq, key=word_freq.get, reverse=True)\n",
        "    ]\n",
        "    return freq_tuple[:100]\n",
        "\n",
        "# print the output of the new task function\n",
        "ran = pipeline.run()\n",
        "print(ran[top_words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOuUFWwQwV5d",
        "outputId": "77684cdb-9cc2-4bb6-924c-6dbff0ac7a13"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "header:  ['objectID', 'created_at', 'url', 'points', 'title']\n",
            "idx:  4\n",
            "[('true', 2), ('goodbye:', 2), ('‘using', 2), ('truecrypt', 2), ('secure’', 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JhPS3GgHwa_A"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}